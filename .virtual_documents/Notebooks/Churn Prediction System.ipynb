import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix
import warnings
warnings.filterwarnings("ignore")


df = pd.read_csv("../Data/Telco-Customer-Churn.csv")
df


df.columns


df.isnull().sum()[df.isnull().sum() > 0]


df.select_dtypes(include='object').columns


# If the column having float values but their data type is showing object then most of the cases blank spaces are their in values 
# So first remove that and then convert data type
df['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan)
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])


print(df['TotalCharges'].isna().sum())
df['TotalCharges'].dtype


df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)


df['TotalCharges'].isna().sum()


cols = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']

for col in cols:
    print((df[col] == 0).sum())


median_val = df['tenure'].median()
df['tenure'] = df['tenure'].replace(0, median_val)


df.drop('customerID', axis=1, inplace=True)


# Convert target variable to binary
df['Churn'] = df['Churn'].replace({'Yes': 1, 'No': 0})


df.select_dtypes(include='object').columns


from sklearn.preprocessing import LabelEncoder, StandardScaler

# Identify categorical columns
cat_cols = df.select_dtypes(include='object').columns

# Apply Label Encoding
le = LabelEncoder()
for col in cat_cols:
    df[col] = le.fit_transform(df[col])


df.head()


X = df.drop('Churn', axis=1)
y = df['Churn']


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)


sc = StandardScaler()
X_train_scaled = sc.fit_transform(X_train)
X_test_scaled = sc.transform(X_test)


from sklearn.linear_model import LogisticRegression

LR = LogisticRegression(max_iter=1000)
LR.fit(X_train_scaled, y_train)


y_pred = LR.predict(X_test)
y_pred


acc = accuracy_score(y_test, y_pred)
acc


cm = confusion_matrix(y_test, y_pred)
cm



rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=10,
    random_state=42
)


rf.fit(X_train, y_train)


y_pred_rf = rf.predict(X_test)
y_prob_rf = rf.predict_proba(X_test)[:, 1]



print("Random Forest")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Precision:", precision_score(y_test, y_pred_rf))
print("Recall:", recall_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))



!pip install xgboost


from xgboost import XGBClassifier

xgb = XGBClassifier(
    n_estimators=200,
    learning_rate=0.05,
    max_depth=5,
    random_satate=42,
    eval_metric='logloss'
)


xgb.fit(X_train, y_train)



y_pred_xgb = xgb.predict(X_test)
y_prob_xgb = xgb.predict_proba(X_test)[:, 1]



rf.fit(X_train, y_train)


importances = rf.feature_importances_
features = X.columns

feature_importance_df = pd.DataFrame({
    'Feature': features,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

feature_importance_df.head(10)


churn_prob_df = X_test.copy()
churn_prob_df['Actual_Churn'] = y_test.values
churn_prob_df['Churn_Probability'] = y_prob_xgb

churn_prob_df.head()


churn_prob_df['Risk_Level'] = churn_prob_df['Churn_Probability'].apply(
    lambda x: 'High' if x > 0.7 else 'Medium' if x > 0.4 else 'Low'
)


plt.hist(churn_prob_df['Churn_Probability'], bins=20)
plt.xlabel("Churn Probability")
plt.ylabel("Number of Customers")
plt.title("Customer Churn Risk Distribution")
plt.show()



